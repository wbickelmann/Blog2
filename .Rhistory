sahdd_test_pred <- knn.cv(sahdd_train.kn, sahdd_train_labels.kn, k = 11, prob = TRUE)
confusionMatrix(sahdd_test_pred,sahdd_train_labels.kn)
sahdd_test_pred <- knn.cv(sahdd_train.kn, sahdd_train_labels.kn, k = 19, prob = TRUE)
confusionMatrix(sahdd_test_pred,sahdd_train_labels.kn)
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.k<-sahdd
sahdd.k$chd<-sahdd.k$chd +1
x<-sahdd.k[-10]
y<-sahdd.k$chd
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'euclidean',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.k<-sahdd
sahdd.k$chd<-sahdd.k$chd +1
x<-sahdd.k[-10]
y<-sahdd.k$chd
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.kn <- as.data.frame(lapply(sahdd[1:9], normalize))
sahdd.kn$chd<-sahdd$chd +1
x<-sahdd.kn[-10]
y<-sahdd.kn$chd
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 19, regression = FALSE, Levels = unique(y), method = 'euclidean',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.kn <- as.data.frame(lapply(sahdd[1:9], normalize))
sahdd.kn$chd<-sahdd$chd +1
x<-sahdd.kn[-10]
y<-sahdd.kn$chd
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'euclidean',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'minkowski',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'mahalanobis',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
library(dplyr)
library(ggplot)
library(ggiraph)
Batting%>%
group_by(playerID)%>%
summarize(Career_HR=sum(HR),Career_SO=sum(SO))%>%
filter(Career_HR>=400)->df
HR_vs_SO<-inner_join(df,Master,by=c("playerID"))%>%
select(nameFirst,nameLast,Career_HR,Career_SO)
#----------------------------------------------------------------------------------
g<-ggplot()+
geom_point(data=HR_vs_SO, aes(x=Career_SO,y=Career_HR, tooltip=nameLast)) +
ggtitle("Career Homeruns vs. Strikeouts for Great Hitters") +
xlab("Strikeouts") +
ylab("Homeruns")
ggiraph(code=print(g),hover_css="fill:white;stroke:black")
## Packages for Social Network Analysis
library(igraph)
library(graphTweets)
### Scraping Twitter Data in R and Text Analysis
library(twitteR)
library(ROAuth)
library(httr)
library(plyr)
library(tm)
library(topicmodels)
### Sentiment Analysis with Twitter Data
library(syuzhet)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
library(caret)
library(MASS)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
length(Accuracies)
summary(Accuracies)
confusionMatrix(pda4_pred,testing$PopSex)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
library(caret)
library(MASS)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
# many columns are Nas
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = trainControl(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = trainControl(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
mult_pred <- predict(mult,newdata = H4A[-inTrain,]))
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = cctrl1)
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- lda(PopSex ~ ., data = training,
prior = c(1/4,1/4,1/4,1/4))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "holdout"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
lapply(Howells[1:87]function(x){})
x=5
x==numeric
x==is.numeric
(x)is.numeric
is.numeric(x)
dist<-function(x){
if(is.numeric(x))
plot(density(x))
}
lapply(Howells[1:87]function(x){})
lapply(Howells[1:87]dist)
lapply(Howells[1:87],dist)
colnames(Howells[2])
dist<-function(x){
if(is.numeric(x))
plot(density(x) main =colnames(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)) main =colnames(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main =colnames(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main =names(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main ="colnames(x)" )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main =paste("title",colnames(x))
}
gss2<-gss %>% #create new dataframe with variables of interest
select(helppoor,sei,year) %>%
filter(!is.na(helppoor),!is.na(sei), year>1999) %>% #filter out NAs for each variable and specify years of interest
group_by(helppoor)
library(ggplot2)
library(dplyr)
library(statsr)
library(miceadds)
load.Rdata(filename = "C:/Users/William/Documents/Datasets/gss.Rdata","gss")
gss.race<-gss%>%
select(helpnot,race,year)%>%
filter(!is.na(helpnot), year>1999)
ggplot(gss.race, aes(x=helpnot, y=race, fill=race)) + geom_bar(stat="identity") + xlab("More or Less Government") + ggtitle("Opinion on Government Role by Race", subtitle = NULL)
gss.degree<-gss%>%
select(degree,marital,year)%>%
filter(!is.na(degree), !is.na(marital), year>1999)
ggplot(gss.degree, aes(x=degree, y=marital, fill=marital)) + geom_bar(stat="identity") + xlab("Degree Type") +ylab("Number of Degree Holders") + ggtitle("Marital Status by Degree", subtitle = NULL)
gss2<-gss %>% #create new dataframe with variables of interest
select(helppoor,sei,year) %>%
filter(!is.na(helppoor),!is.na(sei), year>1999) %>% #filter out NAs for each variable and specify years of interest
group_by(helppoor)
ggplot(gss2, aes(sei)) + geom_histogram(binwidth=0.5) + labs(title="Figure 2: Distribution of SEI Scores",
x = "SEI Score", y= "Number of Respondents")
gss2<-gss %>% #create new dataframe with variables of interest
select(helppoor,sei,year) %>%
filter(!is.na(helppoor),!is.na(sei), year>1999) %>% #filter out NAs for each variable and specify years of interest
group_by(helppoor)
ggplot(gss2, aes(sei)) + geom = "density" + labs(title="Distribution of SEI Scores",
x = "SEI Score", y= "Number of Respondents")
gss.helppoor<-gss %>% #create new dataframe with variables of interest
select(helppoor,sei,year) %>%
filter(!is.na(helppoor),!is.na(sei), year>1999) %>% #filter out NAs for each variable and specify years of interest
group_by(helppoor)
ggplot(gss.helppoor, aes(sei)) + geom = "density" + labs(title="Distribution of SEI Scores",
x = "SEI Score", y= "Number of Respondents")
load("movies.Rdata.gz")
load(url(https://stat.duke.edu/~mc301/data/movies.Rdata))```
load(url(https://stat.duke.edu/~mc301/data/movies.Rdata))
setwd("~/Datasets")
load("movies.rdata")
load.Rdata(filename = "C:/Users/William/Documents/Datasets/movies.rdata",movies)
load.Rdata(filename = "C:/Users/William/Documents/Datasets/movies.rdata","movies")
View(movies)
setwd("~/Blog2")
blogdown::serve_site()
vif(M)
library(car)
vif(M)
M <- lm(imdb_rating ~ title_type + genre + runtime + mpaa_rating + imdb_num_votes + best_pic_nom + best_pic_win,
data = D)
D <- na.omit(movies) %>%
mutate(best_a_win = ifelse(best_actor_win == "yes" | best_actress_win == "yes", "yes", "no")) %>%
select(title_type, genre, runtime, mpaa_rating, thtr_rel_month,
imdb_rating, imdb_num_votes, best_pic_nom, best_pic_win, best_a_win, top200_box)
head(D)
full_model <- lm(imdb_rating ~ title_type + genre + runtime + mpaa_rating + thtr_rel_month + imdb_num_votes + best_pic_nom + best_pic_win + best_a_win + top200_box, data = D)
summary(full_model)$adj.r.squared
M <- lm(imdb_rating ~ title_type + genre + runtime + mpaa_rating + imdb_num_votes + best_pic_nom + best_pic_win,
data = D)
summary(M)
vif(M)
vif(M)
