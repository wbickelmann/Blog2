sahdd.kn <- as.data.frame(lapply(sahdd[1:9], normalize))
sahdd.kn$chd<-sahdd$chd +1
x<-sahdd.kn[-10]
y<-sahdd.kn$chd
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 19, regression = FALSE, Levels = unique(y), method = 'euclidean',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 19, regression = FALSE, Levels = unique(y), method = 'minkowski',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 19, regression = FALSE, Levels = unique(y), method = 'mahalanobis',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
sahdd_test_pred
sahdd_test_pred
knitr::opts_chunk$set(echo = TRUE)
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
install.packages("KernelKnn")
install.packages("ks")
install.packages("class")
library(class)
library(KernelKnn)
library(ks)
library(caret)
install.packages("KernelKnn")
install.packages("ks")
install.packages("class")
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
install.packages("class")
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.n <- as.data.frame(lapply(sahdd[1:10], normalize))
sahdd_train.kn<-sahdd.n[-10]
sahdd_train_labels.kn<-sahdd$chd
sahdd_test_pred <-knn.cv(sahdd_train.kn, sahdd_train_labels.kn, k = 1, prob = TRUE)
confusionMatrix(sahdd_test_pred,sahdd_train_labels.kn)
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.n <- as.data.frame(lapply(sahdd[1:10], normalize))
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.n <- as.data.frame(lapply(sahdd[1:10], normalize))
sahdd_train.kn<-sahdd.n[-10]
sahdd_train_labels.kn<-sahdd$chd
sahdd_test_pred <-knn.cv(sahdd_train.kn, sahdd_train_labels.kn, k = 5, prob = TRUE)
confusionMatrix(sahdd_test_pred,sahdd_train_labels.kn)
sahdd_test_pred <- knn.cv(sahdd_train.kn, sahdd_train_labels.kn, k = 11, prob = TRUE)
confusionMatrix(sahdd_test_pred,sahdd_train_labels.kn)
sahdd_test_pred <- knn.cv(sahdd_train.kn, sahdd_train_labels.kn, k = 19, prob = TRUE)
confusionMatrix(sahdd_test_pred,sahdd_train_labels.kn)
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.k<-sahdd
sahdd.k$chd<-sahdd.k$chd +1
x<-sahdd.k[-10]
y<-sahdd.k$chd
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'euclidean',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.k<-sahdd
sahdd.k$chd<-sahdd.k$chd +1
x<-sahdd.k[-10]
y<-sahdd.k$chd
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.kn <- as.data.frame(lapply(sahdd[1:9], normalize))
sahdd.kn$chd<-sahdd$chd +1
x<-sahdd.kn[-10]
y<-sahdd.kn$chd
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 19, regression = FALSE, Levels = unique(y), method = 'euclidean',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
sahdd <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/sahdd.csv', as.is = T);
sahdd<-sahdd[-1]
sahdd$famhist<-as.numeric(sahdd$famhist == "Present")
sahdd.kn <- as.data.frame(lapply(sahdd[1:9], normalize))
sahdd.kn$chd<-sahdd$chd +1
x<-sahdd.kn[-10]
y<-sahdd.kn$chd
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'euclidean',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'minkowski',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
outKNN <- KernelKnn(x, TEST_data = NULL, as.numeric(y), k = 5, regression = FALSE, Levels = unique(y), method = 'mahalanobis',weights_function = 'exponential')
Classinto <- c(0,0,0)
for (i in seq(length(y)))
{ Classinto[i] <- match(1,match(outKNN[i,], max(outKNN[i,])))
}
confusionMatrix(Classinto,y)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
library(dplyr)
library(ggplot)
library(ggiraph)
Batting%>%
group_by(playerID)%>%
summarize(Career_HR=sum(HR),Career_SO=sum(SO))%>%
filter(Career_HR>=400)->df
HR_vs_SO<-inner_join(df,Master,by=c("playerID"))%>%
select(nameFirst,nameLast,Career_HR,Career_SO)
#----------------------------------------------------------------------------------
g<-ggplot()+
geom_point(data=HR_vs_SO, aes(x=Career_SO,y=Career_HR, tooltip=nameLast)) +
ggtitle("Career Homeruns vs. Strikeouts for Great Hitters") +
xlab("Strikeouts") +
ylab("Homeruns")
ggiraph(code=print(g),hover_css="fill:white;stroke:black")
## Packages for Social Network Analysis
library(igraph)
library(graphTweets)
### Scraping Twitter Data in R and Text Analysis
library(twitteR)
library(ROAuth)
library(httr)
library(plyr)
library(tm)
library(topicmodels)
### Sentiment Analysis with Twitter Data
library(syuzhet)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
table(H4A$PopSex)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
library(caret)
library(MASS)
Accuracies <- c(0.00)
for (i in seq(500))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .70, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
pda4 <- train(PopSex ~ ., data = training, method = "multinom",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(pda4, list(.decay = 3))
pda4_pred <- predict(pda4,newdata = testing)
Accuracies[i] <- confusionMatrix(pda4_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
length(Accuracies)
summary(Accuracies)
confusionMatrix(pda4_pred,testing$PopSex)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
library(caret)
library(MASS)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
# many columns are Nas
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = trainControl(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = trainControl(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
mult_pred <- predict(mult,newdata = H4A[-inTrain,]))
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = cctrl1)
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- lda(PopSex ~ ., data = training,
prior = c(1/4,1/4,1/4,1/4))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ., data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "cv"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(y = H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "lda",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
trControl = trainControl(method = "holdout"))
mult_pred <- predict(mult,newdata = testing)
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Accuracies <- c(0.00)
for (i in seq(100))
{
inTrain <- createDataPartition(H4A$PopSex, p = .75, list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
mult <- train(PopSex ~ ZYB + NOL + FOL + STB + GLS + BBH + AUB + DKB + EKB + ZOR, data = training,
method = "rpart",
parms = list(split = "gini", prior = c(1/4,1/4,1/4,1/4)),
control = rpart.control(minsplit = 20, cp = .01))
mult_pred <- predict(mult,newdata = H4A[-inTrain,])
Accuracies[i] <- confusionMatrix(mult_pred,testing$PopSex)$overall["Accuracy"]}
summary(Accuracies)
plot(density(Accuracies))
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
lapply(Howells[1:87]function(x){})
x=5
x==numeric
x==is.numeric
(x)is.numeric
is.numeric(x)
dist<-function(x){
if(is.numeric(x))
plot(density(x))
}
lapply(Howells[1:87]function(x){})
lapply(Howells[1:87]dist)
lapply(Howells[1:87],dist)
colnames(Howells[2])
dist<-function(x){
if(is.numeric(x))
plot(density(x) main =colnames(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)) main =colnames(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main =colnames(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main =names(x) )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main ="colnames(x)" )
}
lapply(Howells[1:87],dist)
dist<-function(x){
if(is.numeric(x))
plot(density(na.omit(x)), main =paste("title",colnames(x))
}
setwd("~/Blog2")
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
